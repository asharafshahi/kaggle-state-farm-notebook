{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using cuDNN version 5103 on context None\n",
      "Mapped name None to device cuda: Tesla K80 (30FC:00:00.0)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from keras.applications import VGG16\n",
    "#from keras.applications import InceptionResNetV2\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model, Sequential\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import regularizers\n",
    "from keras.layers import Dense, BatchNormalization, Activation, Flatten, Dropout, Conv2D, MaxPooling2D\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.optimizers import Adam, Nadam\n",
    "import numpy as np\n",
    "import bcolz, os\n",
    "from PIL import Image\n",
    "from scipy.misc import toimage\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "train_path = '/home/arman/deep-learning/kaggle-competitions/kaggle-state-farm-notebook/data/train/'\n",
    "valid_path = '/home/arman/deep-learning/kaggle-competitions/kaggle-state-farm-notebook/data/valid/'\n",
    "test_path = '/home/arman/deep-learning/kaggle-competitions/kaggle-state-farm-notebook/data/test/'\n",
    "model_path = '/home/arman/deep-learning/kaggle-competitions/kaggle-state-farm-notebook/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precompute VGG conv layer output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_of_augmented_sets = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18533 images belonging to 10 classes.\n",
      "Found 18533 images belonging to 10 classes.\n",
      "Found 3891 images belonging to 10 classes.\n",
      "Normal train data conv features generated.\n"
     ]
    }
   ],
   "source": [
    "base_model = VGG16(include_top=False, weights='imagenet', input_tensor=None, input_shape=(3, 224, 224), pooling=None, classes=1000)\n",
    "\n",
    "train_gen = image.ImageDataGenerator(rotation_range=15, width_shift_range=0.10, height_shift_range=0.05, # zoom_range=0.1,\n",
    "                                     shear_range=0.1, channel_shift_range=20)\n",
    "gen = image.ImageDataGenerator()\n",
    "train_data = gen.flow_from_directory(train_path, target_size=(224,224), shuffle=False, batch_size=32, class_mode='categorical')\n",
    "train_data_augm = train_gen.flow_from_directory(train_path, target_size=(224,224), shuffle=False, batch_size=32, class_mode='categorical')\n",
    "valid_data = gen.flow_from_directory(valid_path, target_size=(224,224), shuffle=False, batch_size=32, class_mode='categorical')\n",
    "\n",
    "tsteps = int(np.ceil(train_data.samples/32))\n",
    "vsteps = int(np.ceil(valid_data.samples/32))\n",
    "\n",
    "train_output = base_model.predict_generator(train_data, tsteps, workers=3)            # VGG Conv layers output of unaltered train data\n",
    "print('Normal train data conv features generated.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented train data conv features generated.\n"
     ]
    }
   ],
   "source": [
    "train_output_augm = base_model.predict_generator(train_data_augm, number_of_augmented_sets * tsteps, workers=3)   # VGG Conv layers output of augmented train data\n",
    "print('Augmented train data conv features generated.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation data conv features generated.\n",
      "All conv features generated and saved.\n"
     ]
    }
   ],
   "source": [
    "train_output = np.concatenate([train_output, train_output_augm])\n",
    "y_train = to_categorical(train_data.classes)                                          \n",
    "y_train = np.concatenate([y_train] * (number_of_augmented_sets + 1))    \n",
    "    \n",
    "valid_output = base_model.predict_generator(valid_data, vsteps)                       # VGG Conv layers output of validation data\n",
    "print('Validation data conv features generated.')\n",
    "y_valid = to_categorical(valid_data.classes)\n",
    "    \n",
    "c = bcolz.carray(train_output, rootdir=os.path.join(model_path,'VGGTrainOutput.bcolz'), mode='w')\n",
    "c.flush()\n",
    "c = bcolz.carray(valid_output, rootdir=os.path.join(model_path,'VGGValidOutput.bcolz'), mode='w')\n",
    "c.flush()\n",
    "c = bcolz.carray(y_train, rootdir=os.path.join(model_path,'VGGTrainClasses.bcolz'), mode='w')\n",
    "c.flush()\n",
    "c = bcolz.carray(y_valid, rootdir=os.path.join(model_path,'VGGValidClasses.bcolz'), mode='w')\n",
    "c.flush()\n",
    "print('All conv features generated and saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of augments: 2\n",
      "train_output:      (55599, 512, 7, 7)\n",
      "train_output_augm: (37066, 512, 7, 7)\n",
      "valid_output:      (3891, 512, 7, 7)\n",
      "y_train:           (55599, 10)\n",
      "Training data VGG16 conv feature tensor with augmentation is of correct size and match size of y tensor.\n"
     ]
    }
   ],
   "source": [
    "print('number of augments: ' + str(number_of_augmented_sets))\n",
    "print('train_output:      ' + str(train_output.shape))\n",
    "print('train_output_augm: ' + str(train_output_augm.shape))\n",
    "print('valid_output:      ' + str(valid_output.shape))\n",
    "print('y_train:           ' + str(y_train.shape))\n",
    "if (train_output.shape[0] == train_data.samples * (number_of_augmented_sets + 1) and \\\n",
    "    train_output.shape[0] == y_train.shape[0]):\n",
    "        print('Training data VGG16 conv feature tensor with augmentation is of correct size and matches size of y tensor.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully Connected Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dropout_rate = 0.6\n",
    "fc_model = Sequential()\n",
    "fc_model.add(Flatten(input_shape=base_model.layers[-1].output_shape[1:]))\n",
    "fc_model.add(BatchNormalization())\n",
    "fc_model.add(Dense(512, activation='relu')) #  ,kernel_regularizer=regularizers.l2(0.01) ))\n",
    "fc_model.add(Dropout(dropout_rate))\n",
    "fc_model.add(BatchNormalization())\n",
    "fc_model.add(Dense(512, activation='relu')) #, kernel_regularizer=regularizers.l2(0.01)))\n",
    "fc_model.add(Dropout(dropout_rate))\n",
    "fc_model.add(BatchNormalization())\n",
    "fc_model.add(Dense(10, activation='softmax'))\n",
    "fc_model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Code with Precomputed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Put the pre-computed data loading code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55599 samples, validate on 3891 samples\n",
      "Epoch 1/2\n",
      "55599/55599 [==============================] - 18s - loss: 0.9195 - acc: 0.7063 - val_loss: 0.5088 - val_acc: 0.8245\n",
      "Epoch 2/2\n",
      "55599/55599 [==============================] - 17s - loss: 0.2432 - acc: 0.9329 - val_loss: 0.5247 - val_acc: 0.8291\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcd2274a940>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_model.fit(train_output, y_train, epochs=2, validation_data=(valid_output,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55599 samples, validate on 3891 samples\n",
      "Epoch 1/2\n",
      "55599/55599 [==============================] - 17s - loss: 0.1658 - acc: 0.9568 - val_loss: 0.5153 - val_acc: 0.8283\n",
      "Epoch 2/2\n",
      "55599/55599 [==============================] - 17s - loss: 0.1288 - acc: 0.9664 - val_loss: 0.5390 - val_acc: 0.8324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcdd30257f0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_model.optimizer.lr.set_value(0.00001)\n",
    "fc_model.fit(train_output, y_train, epochs=2, validation_data=(valid_output,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_model.save_weights(model_path + 'state_farm.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pseudo Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 79726 images belonging to 1 classes.\n",
      "Partial test data loaded and pseudo-labeled.\n"
     ]
    }
   ],
   "source": [
    "test_set_percent_use = 0.2\n",
    "gen = image.ImageDataGenerator()\n",
    "test_data = gen.flow_from_directory(test_path, target_size=(224,224), shuffle=False, batch_size=32, class_mode=None)\n",
    "tsteps = test_set_percent_use * int(np.ceil(test_data.samples/32))\n",
    "test_output = base_model.predict_generator(test_data, tsteps, workers=3)    # pseudo label 20% of test data - 15,945 images which is about 1/4 of the total training set\n",
    "y_valid_pseudo = fc_model.predict(valid_output)\n",
    "y_test_pseudo = fc_model.predict(test_output)\n",
    "train_combined = np.concatenate([train_output, valid_output, test_output])\n",
    "y_combined = np.concatenate([y_train, y_valid_pseudo, y_test_pseudo])\n",
    "print('Partial test data loaded and pseudo-labeled.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 75458 samples, validate on 3891 samples\n",
      "Epoch 1/1\n",
      "75458/75458 [==============================] - 24s - loss: 0.2690 - acc: 0.9385 - val_loss: 0.5431 - val_acc: 0.8378\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcd2274aa58>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_model.optimizer.lr.set_value(0.00001)\n",
    "fc_model.fit(train_combined, y_combined, epochs=1, validation_data=(valid_output, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Kaggle submission code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 79726 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "gen = image.ImageDataGenerator()\n",
    "test_data = gen.flow_from_directory(test_path, target_size=(224,224), shuffle=False, batch_size=32, class_mode=None)\n",
    "steps = int(np.ceil(test_data.samples/32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_output = base_model.predict_generator(test_data, steps, workers=3)\n",
    "pre_gen = fc_model.predict(test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#probabilities = pred_gen.clip(min=0.05, max=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79726, 10)\n",
      "(79726, 1)\n"
     ]
    }
   ],
   "source": [
    "ids = [element[8:] for element in test_data.filenames]\n",
    "ids = np.asarray(ids).reshape(-1,1)\n",
    "print(pre_gen.shape)\n",
    "print(ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79726, 11)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = np.concatenate([ids,pre_gen], axis=-1)\n",
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "submission_file_name = '/home/arman/deep-learning/kaggle-competitions/kaggle-state-farm-notebook/submission2.csv'\n",
    "np.savetxt(submission_file_name, results, fmt='%5s',delimiter=',', header='img,c0,c1,c2,c3,c4,c5,c6,c7,c8,c9')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "notify_time": "5",
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 275.666666,
   "position": {
    "height": "602px",
    "left": "1370px",
    "right": "20px",
    "top": "198px",
    "width": "600px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
